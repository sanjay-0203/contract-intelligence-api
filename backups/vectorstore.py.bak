# Simple in-memory TF-IDF retriever using sklearn, with persistence of chunks in DB.
from sklearn.feature_extraction.text import TfidfVectorizer
import numpy as np

class Retriever:
    def __init__(self):
        self.vectorizer = None
        self.doc_texts = []  # list of texts (chunks)
        self.ids = []

    def fit(self, texts, ids):
        self.vectorizer = TfidfVectorizer(stop_words='english', max_features=20000)
        X = self.vectorizer.fit_transform(texts)
        self.doc_texts = texts
        self.ids = ids
        self.X = X

    def query(self, q, top_k=3):
        if self.vectorizer is None or len(self.doc_texts)==0:
            return []
        vq = self.vectorizer.transform([q])
        scores = (self.X * vq.T).toarray().ravel()
        idxs = np.argsort(scores)[::-1][:top_k]
        results = []
        for i in idxs:
            if scores[i] <= 0:
                continue
            results.append({'id': self.ids[i], 'score': float(scores[i]), 'text': self.doc_texts[i]})
        return results

# single global retriever instance
RETRIEVER = Retriever()